{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3414d106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a006aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport time\\nfrom functools import wraps\\n\\nimport numpy as np\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\\n\\nfrom tensorflow.keras.layers import (\\n    Activation,\\n    Conv1D,\\n    Conv2D,\\n    Dense,\\n    GlobalAveragePooling2D,\\n    MaxPooling2D,\\n    Flatten,\\n)\\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.utils import set_random_seed\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport time\\nfrom functools import wraps\\n\\nimport numpy as np\\nfrom sklearn.datasets import load_digits\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\\n\\nfrom tensorflow.keras.layers import (\\n    Activation,\\n    Conv1D,\\n    Conv2D,\\n    Dense,\\n    GlobalAveragePooling2D,\\n    MaxPooling2D,\\n    Flatten,\\n)\\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.utils import set_random_seed\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    ")\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import set_random_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8b57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def timing(f):\\n    @wraps(f)\\n    def inner(*args, **kwargs):\\n        start = time.perf_counter()\\n        val = f(*args, **kwargs)\\n        end = time.perf_counter()\\n        print(f\\\"Function {f.__qualname__} finished in {end-start:.2f} seconds.\\\")\\n        return val\\n\\n    return inner\";\n",
       "                var nbb_formatted_code = \"def timing(f):\\n    @wraps(f)\\n    def inner(*args, **kwargs):\\n        start = time.perf_counter()\\n        val = f(*args, **kwargs)\\n        end = time.perf_counter()\\n        print(f\\\"Function {f.__qualname__} finished in {end-start:.2f} seconds.\\\")\\n        return val\\n\\n    return inner\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        val = f(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"Function {f.__qualname__} finished in {end-start:.2f} seconds.\")\n",
    "        return val\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877483c8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e008f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"data = load_digits()\\n\\nX = data[\\\"data\\\"] / 256\\ny = data[\\\"target\\\"]\";\n",
       "                var nbb_formatted_code = \"data = load_digits()\\n\\nX = data[\\\"data\\\"] / 256\\ny = data[\\\"target\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_digits()\n",
    "\n",
    "X = data[\"data\"] / 256\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09c7ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"X_train, X_test, y_train, y_test = train_test_split(\\n    X, y, stratify=y, test_size=0.1, random_state=42\\n)\";\n",
       "                var nbb_formatted_code = \"X_train, X_test, y_train, y_test = train_test_split(\\n    X, y, stratify=y, test_size=0.1, random_state=42\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c888b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"NEW_SHAPE_TRAIN = (X_train.shape[0], 8, 8, 1)\\nNEW_SHAPE_TEST = (X_test.shape[0], 8, 8, 1)\\n\\nX_train_reshaped = X_train.reshape(NEW_SHAPE_TRAIN)\\nX_test_reshaped = X_test.reshape(NEW_SHAPE_TEST)\";\n",
       "                var nbb_formatted_code = \"NEW_SHAPE_TRAIN = (X_train.shape[0], 8, 8, 1)\\nNEW_SHAPE_TEST = (X_test.shape[0], 8, 8, 1)\\n\\nX_train_reshaped = X_train.reshape(NEW_SHAPE_TRAIN)\\nX_test_reshaped = X_test.reshape(NEW_SHAPE_TEST)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NEW_SHAPE_TRAIN = (X_train.shape[0], 8, 8, 1)\n",
    "NEW_SHAPE_TEST = (X_test.shape[0], 8, 8, 1)\n",
    "\n",
    "X_train_reshaped = X_train.reshape(NEW_SHAPE_TRAIN)\n",
    "X_test_reshaped = X_test.reshape(NEW_SHAPE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad171",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabd3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 8, 8, 4)           8         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,578\n",
      "Trainable params: 2,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"set_random_seed(42)\\nmodel = Sequential(\\n    [\\n        Conv2D(\\n            filters=4,\\n            kernel_size=(1, 1),\\n            padding=\\\"valid\\\",\\n            strides=1,\\n            input_shape=((8, 8, 1)),\\n        ),\\n        Flatten(),\\n        #         Dense(units=15, activation=\\\"relu\\\"),\\n        Dense(units=10, activation=\\\"softmax\\\"),\\n    ]\\n)\\n\\nLOSS = SparseCategoricalCrossentropy()\\nMETRICS = [\\\"accuracy\\\"]\\nOPTIMIZER = Adam(learning_rate=0.001)\\n\\n\\nmodel.compile(loss=LOSS, metrics=METRICS, optimizer=OPTIMIZER)\\nmodel.summary()\";\n",
       "                var nbb_formatted_code = \"set_random_seed(42)\\nmodel = Sequential(\\n    [\\n        Conv2D(\\n            filters=4,\\n            kernel_size=(1, 1),\\n            padding=\\\"valid\\\",\\n            strides=1,\\n            input_shape=((8, 8, 1)),\\n        ),\\n        Flatten(),\\n        #         Dense(units=15, activation=\\\"relu\\\"),\\n        Dense(units=10, activation=\\\"softmax\\\"),\\n    ]\\n)\\n\\nLOSS = SparseCategoricalCrossentropy()\\nMETRICS = [\\\"accuracy\\\"]\\nOPTIMIZER = Adam(learning_rate=0.001)\\n\\n\\nmodel.compile(loss=LOSS, metrics=METRICS, optimizer=OPTIMIZER)\\nmodel.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_random_seed(42)\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(\n",
    "            filters=4,\n",
    "            kernel_size=(1, 1),\n",
    "            padding=\"valid\",\n",
    "            strides=1,\n",
    "            input_shape=((8, 8, 1)),\n",
    "        ),\n",
    "        Flatten(),\n",
    "        #         Dense(units=15, activation=\"relu\"),\n",
    "        Dense(units=10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "LOSS = SparseCategoricalCrossentropy()\n",
    "METRICS = [\"accuracy\"]\n",
    "OPTIMIZER = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(loss=LOSS, metrics=METRICS, optimizer=OPTIMIZER)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad4fa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"@timing\\ndef train(x, y, **kwargs):\\n    history = model.fit(x, y, **kwargs)\\n    return history\";\n",
       "                var nbb_formatted_code = \"@timing\\ndef train(x, y, **kwargs):\\n    history = model.fit(x, y, **kwargs)\\n    return history\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timing\n",
    "def train(x, y, **kwargs):\n",
    "    history = model.fit(x, y, **kwargs)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b65468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"early_stopping = EarlyStopping(\\n    mode=\\\"auto\\\",\\n    monitor=\\\"val_loss\\\",\\n    patience=3,\\n    min_delta=0,\\n    restore_best_weights=False,\\n    verbose=1,\\n)\\n\\nreduce_lr = ReduceLROnPlateau(\\n    mode=\\\"auto\\\",\\n    monitor=\\\"val_loss\\\",\\n    factor=0.1,\\n    patience=1,\\n    min_delta=0,\\n    min_lr=1e-08,\\n    cooldown=0,\\n    verbose=1,\\n)\\n\\ntensorboard = TensorBoard(log_dir=\\\"./logs_tensorboard\\\", write_graph=True)\";\n",
       "                var nbb_formatted_code = \"early_stopping = EarlyStopping(\\n    mode=\\\"auto\\\",\\n    monitor=\\\"val_loss\\\",\\n    patience=3,\\n    min_delta=0,\\n    restore_best_weights=False,\\n    verbose=1,\\n)\\n\\nreduce_lr = ReduceLROnPlateau(\\n    mode=\\\"auto\\\",\\n    monitor=\\\"val_loss\\\",\\n    factor=0.1,\\n    patience=1,\\n    min_delta=0,\\n    min_lr=1e-08,\\n    cooldown=0,\\n    verbose=1,\\n)\\n\\ntensorboard = TensorBoard(log_dir=\\\"./logs_tensorboard\\\", write_graph=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    mode=\"auto\",\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_delta=0,\n",
    "    restore_best_weights=False,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    mode=\"auto\",\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=1,\n",
    "    min_delta=0,\n",
    "    min_lr=1e-08,\n",
    "    cooldown=0,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs_tensorboard\", write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15577b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 3s 13ms/step - loss: 2.2954 - accuracy: 0.1515 - val_loss: 2.2807 - val_accuracy: 0.3278 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.2716 - accuracy: 0.3970 - val_loss: 2.2557 - val_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.2450 - accuracy: 0.5665 - val_loss: 2.2272 - val_accuracy: 0.6611 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.2149 - accuracy: 0.6729 - val_loss: 2.1948 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.1813 - accuracy: 0.7570 - val_loss: 2.1586 - val_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.1438 - accuracy: 0.8312 - val_loss: 2.1193 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.1031 - accuracy: 0.8677 - val_loss: 2.0760 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.0586 - accuracy: 0.8763 - val_loss: 2.0298 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.0117 - accuracy: 0.8701 - val_loss: 1.9811 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.9616 - accuracy: 0.8763 - val_loss: 1.9295 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.9096 - accuracy: 0.8745 - val_loss: 1.8756 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.8551 - accuracy: 0.8776 - val_loss: 1.8198 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.7988 - accuracy: 0.8782 - val_loss: 1.7630 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.7419 - accuracy: 0.8738 - val_loss: 1.7049 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6833 - accuracy: 0.8782 - val_loss: 1.6459 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6244 - accuracy: 0.8881 - val_loss: 1.5870 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.5653 - accuracy: 0.8887 - val_loss: 1.5281 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.5063 - accuracy: 0.8881 - val_loss: 1.4693 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.4480 - accuracy: 0.8881 - val_loss: 1.4111 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.3909 - accuracy: 0.8918 - val_loss: 1.3545 - val_accuracy: 0.8611 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.3352 - accuracy: 0.8930 - val_loss: 1.2990 - val_accuracy: 0.8611 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.2808 - accuracy: 0.8936 - val_loss: 1.2455 - val_accuracy: 0.8611 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.2272 - accuracy: 0.8918 - val_loss: 1.1939 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.1762 - accuracy: 0.8955 - val_loss: 1.1432 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.1270 - accuracy: 0.8973 - val_loss: 1.0955 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0802 - accuracy: 0.9004 - val_loss: 1.0493 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.0349 - accuracy: 0.9011 - val_loss: 1.0052 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.9921 - accuracy: 0.9017 - val_loss: 0.9639 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9515 - accuracy: 0.9023 - val_loss: 0.9245 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.9130 - accuracy: 0.9041 - val_loss: 0.8871 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.9054 - val_loss: 0.8523 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8424 - accuracy: 0.9072 - val_loss: 0.8186 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8100 - accuracy: 0.9091 - val_loss: 0.7868 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7795 - accuracy: 0.9091 - val_loss: 0.7577 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7519 - accuracy: 0.9103 - val_loss: 0.7292 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7239 - accuracy: 0.9153 - val_loss: 0.7038 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.9116 - val_loss: 0.6787 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.9122 - val_loss: 0.6560 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.9140 - val_loss: 0.6335 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.9165 - val_loss: 0.6134 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.9165 - val_loss: 0.5941 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.9184 - val_loss: 0.5758 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.9196 - val_loss: 0.5587 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.9202 - val_loss: 0.5419 - val_accuracy: 0.9056 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.9221 - val_loss: 0.5261 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.9215 - val_loss: 0.5115 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.9233 - val_loss: 0.4976 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.9258 - val_loss: 0.4839 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.9276 - val_loss: 0.4721 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.9276 - val_loss: 0.4592 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.9276 - val_loss: 0.4487 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.9295 - val_loss: 0.4378 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.9301 - val_loss: 0.4281 - val_accuracy: 0.9167 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.9314 - val_loss: 0.4185 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.9301 - val_loss: 0.4087 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.9326 - val_loss: 0.4007 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.9326 - val_loss: 0.3918 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.9332 - val_loss: 0.3846 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.9320 - val_loss: 0.3756 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.9344 - val_loss: 0.3686 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.9351 - val_loss: 0.3612 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.9363 - val_loss: 0.3549 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.9363 - val_loss: 0.3482 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.9369 - val_loss: 0.3412 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.9369 - val_loss: 0.3347 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.9394 - val_loss: 0.3293 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.9382 - val_loss: 0.3244 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.9388 - val_loss: 0.3184 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.9388 - val_loss: 0.3133 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.9394 - val_loss: 0.3076 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3070 - accuracy: 0.9388 - val_loss: 0.3031 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.9412 - val_loss: 0.2990 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9419 - val_loss: 0.2941 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2922 - accuracy: 0.9425 - val_loss: 0.2897 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.9437 - val_loss: 0.2860 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9443 - val_loss: 0.2814 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.9450 - val_loss: 0.2775 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2746 - accuracy: 0.9468 - val_loss: 0.2724 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9462 - val_loss: 0.2701 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2666 - accuracy: 0.9468 - val_loss: 0.2654 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9468 - val_loss: 0.2626 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.9474 - val_loss: 0.2580 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.9462 - val_loss: 0.2558 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.9474 - val_loss: 0.2522 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.9481 - val_loss: 0.2498 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.9487 - val_loss: 0.2465 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9481 - val_loss: 0.2431 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9487 - val_loss: 0.2411 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.2356 - accuracy: 0.9493 - val_loss: 0.2380 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.9493 - val_loss: 0.2354 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2296 - accuracy: 0.9493 - val_loss: 0.2348 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2266 - accuracy: 0.9505 - val_loss: 0.2309 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9530 - val_loss: 0.2283 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2210 - accuracy: 0.9505 - val_loss: 0.2262 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2185 - accuracy: 0.9530 - val_loss: 0.2233 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9530 - val_loss: 0.2213 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.9536 - val_loss: 0.2183 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2108 - accuracy: 0.9536 - val_loss: 0.2165 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9549 - val_loss: 0.2143 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2061 - accuracy: 0.9542 - val_loss: 0.2132 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2035 - accuracy: 0.9549 - val_loss: 0.2103 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2015 - accuracy: 0.9542 - val_loss: 0.2089 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9542 - val_loss: 0.2061 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1968 - accuracy: 0.9561 - val_loss: 0.2046 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9555 - val_loss: 0.2036 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9549 - val_loss: 0.2013 - val_accuracy: 0.9500 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1904 - accuracy: 0.9561 - val_loss: 0.1991 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1885 - accuracy: 0.9579 - val_loss: 0.1982 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9573 - val_loss: 0.1963 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1844 - accuracy: 0.9573 - val_loss: 0.1947 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9567 - val_loss: 0.1929 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1917 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9573 - val_loss: 0.1898 - val_accuracy: 0.9500 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1773 - accuracy: 0.9573 - val_loss: 0.1882 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1755 - accuracy: 0.9573 - val_loss: 0.1881 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9604 - val_loss: 0.1859 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9598 - val_loss: 0.1838 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1703 - accuracy: 0.9586 - val_loss: 0.1832 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1689 - accuracy: 0.9598 - val_loss: 0.1826 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9598 - val_loss: 0.1817 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9610 - val_loss: 0.1793 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9617 - val_loss: 0.1789 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1628 - accuracy: 0.9610 - val_loss: 0.1760 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "19/26 [====================>.........] - ETA: 0s - loss: 0.1599 - accuracy: 0.9646\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.9617 - val_loss: 0.1779 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.1488 - accuracy: 0.9623\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1597 - accuracy: 0.9629 - val_loss: 0.1774 - val_accuracy: 0.9556 - lr: 1.0000e-04\n",
      "Epoch 126/500\n",
      "15/26 [================>.............] - ETA: 0s - loss: 0.1635 - accuracy: 0.9635\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9641 - val_loss: 0.1773 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
      "Epoch 126: early stopping\n",
      "Function train finished in 19.32 seconds.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"history = train(\\n    X_train_reshaped,\\n    y_train,\\n    validation_data=(X_test_reshaped, y_test),\\n    batch_size=64,\\n    epochs=500,\\n    callbacks=[reduce_lr, early_stopping, tensorboard],\\n)\";\n",
       "                var nbb_formatted_code = \"history = train(\\n    X_train_reshaped,\\n    y_train,\\n    validation_data=(X_test_reshaped, y_test),\\n    batch_size=64,\\n    epochs=500,\\n    callbacks=[reduce_lr, early_stopping, tensorboard],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = train(\n",
    "    X_train_reshaped,\n",
    "    y_train,\n",
    "    validation_data=(X_test_reshaped, y_test),\n",
    "    batch_size=64,\n",
    "    epochs=500,\n",
    "    callbacks=[reduce_lr, early_stopping, tensorboard],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
