{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7744719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c783bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"import random\\n\\nimport gym\\nimport numpy as np\\n\\nfrom gym import Env\\nfrom gym.spaces import Box, Dict, Discrete, MultiBinary, MultiDiscrete, Tuple\\nfrom stable_baselines3 import PPO\\nfrom stable_baselines3.common.vec_env import DummyVecEnv\\nfrom stable_baselines3.common.evaluation import evaluate_policy\";\n",
       "                var nbb_formatted_code = \"import random\\n\\nimport gym\\nimport numpy as np\\n\\nfrom gym import Env\\nfrom gym.spaces import Box, Dict, Discrete, MultiBinary, MultiDiscrete, Tuple\\nfrom stable_baselines3 import PPO\\nfrom stable_baselines3.common.vec_env import DummyVecEnv\\nfrom stable_baselines3.common.evaluation import evaluate_policy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Dict, Discrete, MultiBinary, MultiDiscrete, Tuple\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "6f0c75c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 429;\n",
       "                var nbb_unformatted_code = \"class ShowerEnv(Env):\\n    def __init__(self):\\n        self.action_space = Discrete(3)\\n        self.observation_space = Box(low=-100, high=100, shape=(1,))\\n        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\\n        self.shower_length = 60\\n\\n    def step(self, action):\\n        # apply temperature adjustment\\n        self.state += action - 1\\n\\n        # decrease shower time\\n        self.shower_length -= 1\\n\\n        # Calculate reward\\n        if self.state >= 37 and self.state <= 39:\\n            reward = 1\\n        else:\\n            reward = -1\\n\\n        if self.shower_length <= 0:\\n            done = True\\n        else:\\n            done = False\\n\\n        info = {}\\n\\n        return self.state, reward, done, info\\n\\n    def render(self):\\n        pass\\n\\n    def reset(self):\\n        self.shower_length = 60\\n        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\\n        return self.state\\n\\n\\nenv = ShowerEnv()\";\n",
       "                var nbb_formatted_code = \"class ShowerEnv(Env):\\n    def __init__(self):\\n        self.action_space = Discrete(3)\\n        self.observation_space = Box(low=-100, high=100, shape=(1,))\\n        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\\n        self.shower_length = 60\\n\\n    def step(self, action):\\n        # apply temperature adjustment\\n        self.state += action - 1\\n\\n        # decrease shower time\\n        self.shower_length -= 1\\n\\n        # Calculate reward\\n        if self.state >= 37 and self.state <= 39:\\n            reward = 1\\n        else:\\n            reward = -1\\n\\n        if self.shower_length <= 0:\\n            done = True\\n        else:\\n            done = False\\n\\n        info = {}\\n\\n        return self.state, reward, done, info\\n\\n    def render(self):\\n        pass\\n\\n    def reset(self):\\n        self.shower_length = 60\\n        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\\n        return self.state\\n\\n\\nenv = ShowerEnv()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(low=-100, high=100, shape=(1,))\n",
    "        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\n",
    "        self.shower_length = 60\n",
    "\n",
    "    def step(self, action):\n",
    "        # apply temperature adjustment\n",
    "        self.state += action - 1\n",
    "\n",
    "        # decrease shower time\n",
    "        self.shower_length -= 1\n",
    "\n",
    "        # Calculate reward\n",
    "        if self.state >= 37 and self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.shower_length = 60\n",
    "        self.state = np.array([38 + random.randint(-3, 3)]).astype(float)\n",
    "        return self.state\n",
    "\n",
    "\n",
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "36afd06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 14\n",
      "Episode: 2, Score: -60\n",
      "Episode: 3, Score: -34\n",
      "Episode: 4, Score: -22\n",
      "Episode: 5, Score: -60\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 427;\n",
       "                var nbb_unformatted_code = \"episodes = 5\\nfor episode in range(1, episodes + 1):\\n    state = env.reset()\\n    done = False\\n    score = 0\\n\\n    while not done:\\n        env.render()\\n        action = env.action_space.sample()\\n        n_state, reward, done, info = env.step(action)\\n        score += reward\\n\\n    print(f\\\"Episode: {episode}, Score: {score}\\\")\\nenv.close()\";\n",
       "                var nbb_formatted_code = \"episodes = 5\\nfor episode in range(1, episodes + 1):\\n    state = env.reset()\\n    done = False\\n    score = 0\\n\\n    while not done:\\n        env.render()\\n        action = env.action_space.sample()\\n        n_state, reward, done, info = env.step(action)\\n        score += reward\\n\\n    print(f\\\"Episode: {episode}, Score: {score}\\\")\\nenv.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Episode: {episode}, Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca66ea",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "6231fd02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -24.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 2061     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -25.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012462255 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000785    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -25.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1242         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069139446 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.0037      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 65.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1191        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010254205 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 3.82e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1163        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013647966 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.000156    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -30.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1145        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007207262 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -4.03e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -27.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1133        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006048401 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -7.15e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 76.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -23.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1124         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051115137 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 2.59e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    value_loss           | 82.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -22.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1112        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011936747 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.000244   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 71.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -23.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1105         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029197505 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.00145      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -3e-05       |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2874151b580>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 428;\n",
       "                var nbb_unformatted_code = \"env.reset()\\nmodel = PPO(\\\"MlpPolicy\\\", env=env, verbose=1)\\nmodel.learn(total_timesteps=20000)\";\n",
       "                var nbb_formatted_code = \"env.reset()\\nmodel = PPO(\\\"MlpPolicy\\\", env=env, verbose=1)\\nmodel.learn(total_timesteps=20000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "model = PPO(\"MlpPolicy\", env=env, verbose=1)\n",
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "e754817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-24.0, 54.99090833947008)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 446;\n",
       "                var nbb_unformatted_code = \"evaluate_policy(model, env, n_eval_episodes=10, render=False)\";\n",
       "                var nbb_formatted_code = \"evaluate_policy(model, env, n_eval_episodes=10, render=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
